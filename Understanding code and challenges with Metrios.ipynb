{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c16612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c70d4f",
   "metadata": {},
   "source": [
    "# When there is no missing values in the input time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8897f81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assume we input a time series, [batchSize= 1, column number = 1, length of the series = 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2694,  0.9239, -0.6867,  0.8838,  0.0558]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 1, 5)\n",
    "print(\"Assume we input a time series, [batchSize= 1, column number = 1, length of the series = 5]\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2f9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chomp1D(x, chomp_size):\n",
    "    return x[:, :, :-chomp_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b0750",
   "metadata": {},
   "source": [
    "Note: since weightnorm and relu activation function do not change shape, we omit them in this testing code for better clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f24a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several Conv1 layers in the whole network. All of the conv1's out_channels=40 except the last conv1's out_channel=320.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conv1d(1, 320, kernel_size=(3,), stride=(1,), padding=(2,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are several Conv1 layers in the whole network. All of the conv1's out_channels=40 except the last conv1's out_channel=320.\")\n",
    "\n",
    "conv1 = torch.nn.Conv1d(in_channels=1, out_channels=320, kernel_size=3, padding=2, dilation=1)\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbea14e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2628, -0.5828,  0.4189,  ...,  0.3485, -0.3102, -0.1636],\n",
       "         [-0.0229, -0.2682,  0.5610,  ...,  0.4368, -0.1745,  0.0161],\n",
       "         [ 0.4144,  0.7051, -0.1756,  ...,  0.1367,  0.8880,  0.5366],\n",
       "         ...,\n",
       "         [ 0.0023, -0.6713, -0.5978,  ..., -0.5608,  0.0290, -0.3106],\n",
       "         [-0.3060, -0.2412, -0.8485,  ..., -0.7783, -0.2383, -0.4141],\n",
       "         [ 0.2669, -0.2945,  0.3951,  ..., -0.2489, -0.8139, -0.3367]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_conv1 = conv1(x)\n",
    "print(output_conv1.shape)\n",
    "output_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "164f1dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1731, -0.0301, -0.2691,  0.2169,  0.7169],\n",
       "         [ 0.2299, -0.4404, -0.4675,  0.3638, -0.0301],\n",
       "         [ 0.1225,  0.3330, -0.3448, -0.5038,  0.6929],\n",
       "         ...,\n",
       "         [-0.2150,  0.1279,  0.5057,  0.0972, -0.2664],\n",
       "         [-0.0068,  0.1445, -0.5320, -0.8261,  0.3189],\n",
       "         [ 0.7271,  1.1957,  0.6107, -0.0762,  1.1329]]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_chomp1D = chomp1D(output_conv1, 2)\n",
    "print(output_chomp1D.shape)\n",
    "output_chomp1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e94529a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320, 1])\n",
      "As we can see, each input single value turn into 320 values, and these are the important features of this single value. The length of the input series is disregarded, ie 5 becomes 1. So now the input series is represented by 1 number that has 320 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.1693e-01],\n",
       "         [ 3.6379e-01],\n",
       "         [ 6.9294e-01],\n",
       "         [ 7.1109e-01],\n",
       "         [ 4.5150e-01],\n",
       "         [ 5.8228e-01],\n",
       "         [ 7.4167e-01],\n",
       "         [-1.8462e-02],\n",
       "         [ 3.5803e-01],\n",
       "         [ 1.2853e-02],\n",
       "         [ 8.3715e-01],\n",
       "         [ 9.6151e-01],\n",
       "         [ 1.3426e+00],\n",
       "         [ 1.4026e-01],\n",
       "         [ 1.3590e+00],\n",
       "         [-2.7623e-01],\n",
       "         [ 6.8790e-01],\n",
       "         [ 4.7019e-01],\n",
       "         [ 1.1830e+00],\n",
       "         [ 2.5140e-01],\n",
       "         [ 1.9567e-01],\n",
       "         [ 1.4597e+00],\n",
       "         [ 1.3383e+00],\n",
       "         [-5.3759e-01],\n",
       "         [ 5.4988e-01],\n",
       "         [ 7.0733e-01],\n",
       "         [-1.1598e-01],\n",
       "         [ 7.1554e-01],\n",
       "         [ 1.3418e+00],\n",
       "         [ 1.6129e+00],\n",
       "         [ 8.1021e-01],\n",
       "         [ 1.6692e+00],\n",
       "         [ 4.7325e-01],\n",
       "         [ 2.4416e-01],\n",
       "         [ 8.3897e-01],\n",
       "         [ 1.8066e+00],\n",
       "         [ 1.0460e+00],\n",
       "         [ 3.9240e-01],\n",
       "         [-2.5766e-01],\n",
       "         [ 5.2076e-01],\n",
       "         [ 6.9135e-01],\n",
       "         [ 8.3081e-01],\n",
       "         [ 1.3088e+00],\n",
       "         [ 1.8339e-01],\n",
       "         [-2.5171e-01],\n",
       "         [ 5.8868e-01],\n",
       "         [ 1.4208e+00],\n",
       "         [ 1.2572e+00],\n",
       "         [ 3.3689e-01],\n",
       "         [ 9.2980e-02],\n",
       "         [ 1.6370e-01],\n",
       "         [ 8.2502e-01],\n",
       "         [ 5.7390e-01],\n",
       "         [ 1.6110e+00],\n",
       "         [ 1.0459e+00],\n",
       "         [ 3.0195e-01],\n",
       "         [ 1.0264e+00],\n",
       "         [-1.5252e-01],\n",
       "         [ 1.2383e+00],\n",
       "         [ 2.2057e-01],\n",
       "         [ 4.7698e-01],\n",
       "         [ 6.1817e-01],\n",
       "         [ 6.3510e-01],\n",
       "         [ 6.7006e-01],\n",
       "         [-4.9933e-01],\n",
       "         [-4.6938e-02],\n",
       "         [ 1.9735e+00],\n",
       "         [ 1.8451e+00],\n",
       "         [ 5.5563e-01],\n",
       "         [ 2.3449e-01],\n",
       "         [ 7.9858e-01],\n",
       "         [ 7.7994e-01],\n",
       "         [ 6.1611e-01],\n",
       "         [ 4.7622e-01],\n",
       "         [ 6.5269e-02],\n",
       "         [ 5.9199e-01],\n",
       "         [ 6.9591e-01],\n",
       "         [ 5.5791e-01],\n",
       "         [-3.6287e-01],\n",
       "         [ 5.2771e-01],\n",
       "         [ 6.5516e-01],\n",
       "         [ 8.0739e-01],\n",
       "         [ 7.6625e-01],\n",
       "         [ 4.6984e-01],\n",
       "         [ 1.7361e-01],\n",
       "         [ 6.8724e-01],\n",
       "         [ 4.2031e-01],\n",
       "         [ 4.6878e-01],\n",
       "         [ 6.8430e-01],\n",
       "         [ 3.5087e-01],\n",
       "         [ 2.7581e-01],\n",
       "         [ 3.9147e-01],\n",
       "         [ 7.9459e-01],\n",
       "         [ 9.4337e-01],\n",
       "         [ 1.1149e+00],\n",
       "         [ 2.2130e-01],\n",
       "         [ 4.6995e-01],\n",
       "         [ 9.4343e-01],\n",
       "         [ 6.5834e-01],\n",
       "         [-1.6554e-02],\n",
       "         [-3.1730e-01],\n",
       "         [ 1.4212e+00],\n",
       "         [ 1.1191e+00],\n",
       "         [ 8.7511e-01],\n",
       "         [-7.1412e-03],\n",
       "         [ 5.8477e-01],\n",
       "         [ 1.1458e+00],\n",
       "         [-1.8040e-01],\n",
       "         [-4.5143e-01],\n",
       "         [-4.6301e-01],\n",
       "         [ 1.0733e+00],\n",
       "         [ 1.0212e+00],\n",
       "         [ 3.5933e-01],\n",
       "         [ 2.8048e-01],\n",
       "         [ 7.4088e-01],\n",
       "         [-3.4165e-01],\n",
       "         [ 4.2311e-01],\n",
       "         [ 1.6497e+00],\n",
       "         [-3.7569e-01],\n",
       "         [ 2.4492e-01],\n",
       "         [ 7.1424e-01],\n",
       "         [-2.5414e-01],\n",
       "         [ 4.9241e-01],\n",
       "         [ 1.1746e+00],\n",
       "         [ 2.3797e-01],\n",
       "         [ 9.0168e-01],\n",
       "         [ 2.7510e-01],\n",
       "         [ 6.3755e-01],\n",
       "         [ 1.1459e+00],\n",
       "         [ 6.0371e-01],\n",
       "         [ 2.8589e-01],\n",
       "         [ 3.1010e-01],\n",
       "         [ 4.7753e-01],\n",
       "         [ 2.8079e-01],\n",
       "         [ 2.5565e-01],\n",
       "         [ 1.1841e+00],\n",
       "         [-8.0069e-02],\n",
       "         [ 1.2626e+00],\n",
       "         [-2.7090e-01],\n",
       "         [ 1.7835e+00],\n",
       "         [ 1.0922e+00],\n",
       "         [-4.6702e-01],\n",
       "         [ 1.6503e+00],\n",
       "         [ 1.5074e+00],\n",
       "         [ 8.1328e-01],\n",
       "         [ 1.9918e+00],\n",
       "         [-2.9711e-01],\n",
       "         [-7.9050e-02],\n",
       "         [ 1.8285e+00],\n",
       "         [-4.3808e-01],\n",
       "         [-1.7964e-02],\n",
       "         [ 1.6626e-01],\n",
       "         [ 3.9343e-01],\n",
       "         [ 6.5753e-01],\n",
       "         [ 9.0115e-01],\n",
       "         [-4.6730e-01],\n",
       "         [-2.0470e-01],\n",
       "         [ 1.0665e+00],\n",
       "         [ 7.2065e-01],\n",
       "         [ 1.5306e-01],\n",
       "         [ 3.1741e-02],\n",
       "         [ 1.1100e+00],\n",
       "         [-1.4286e-01],\n",
       "         [ 6.3447e-01],\n",
       "         [-2.7045e-01],\n",
       "         [ 8.1055e-02],\n",
       "         [ 1.1882e+00],\n",
       "         [ 6.8817e-02],\n",
       "         [ 7.6552e-01],\n",
       "         [ 2.4762e-01],\n",
       "         [ 3.1006e-01],\n",
       "         [ 9.9973e-01],\n",
       "         [ 1.7261e-01],\n",
       "         [ 8.4041e-01],\n",
       "         [ 2.3737e-01],\n",
       "         [ 1.3231e+00],\n",
       "         [-2.2319e-01],\n",
       "         [ 6.2816e-01],\n",
       "         [ 1.8352e-01],\n",
       "         [ 2.7439e-01],\n",
       "         [ 4.7874e-01],\n",
       "         [-2.2742e-01],\n",
       "         [ 2.1543e-01],\n",
       "         [ 1.0492e+00],\n",
       "         [ 4.9130e-01],\n",
       "         [ 1.3470e+00],\n",
       "         [ 1.0780e+00],\n",
       "         [ 7.4307e-01],\n",
       "         [ 6.7779e-01],\n",
       "         [ 4.0288e-01],\n",
       "         [ 1.0736e+00],\n",
       "         [ 1.1005e+00],\n",
       "         [ 3.7557e-01],\n",
       "         [ 1.0527e+00],\n",
       "         [ 8.0307e-01],\n",
       "         [ 1.8311e-01],\n",
       "         [-1.8056e-01],\n",
       "         [ 4.3792e-01],\n",
       "         [ 1.5269e-03],\n",
       "         [-3.3987e-02],\n",
       "         [ 9.6113e-01],\n",
       "         [ 3.6616e-01],\n",
       "         [ 3.3063e-01],\n",
       "         [ 9.1808e-01],\n",
       "         [ 3.5678e-01],\n",
       "         [ 9.5070e-01],\n",
       "         [ 2.6794e-01],\n",
       "         [ 4.7959e-01],\n",
       "         [ 2.3536e-01],\n",
       "         [-5.0524e-01],\n",
       "         [ 5.8467e-01],\n",
       "         [ 5.2341e-01],\n",
       "         [ 3.3695e-01],\n",
       "         [ 3.3868e-01],\n",
       "         [-2.3377e-01],\n",
       "         [ 4.1551e-01],\n",
       "         [ 9.3181e-01],\n",
       "         [ 2.7498e-01],\n",
       "         [-5.2482e-01],\n",
       "         [ 5.0299e-01],\n",
       "         [ 1.4434e+00],\n",
       "         [ 1.0428e+00],\n",
       "         [ 9.3373e-01],\n",
       "         [ 1.3503e+00],\n",
       "         [ 7.6912e-01],\n",
       "         [ 7.6583e-01],\n",
       "         [-1.8326e-01],\n",
       "         [ 1.6715e+00],\n",
       "         [ 6.0450e-01],\n",
       "         [ 3.8164e-01],\n",
       "         [ 1.4504e+00],\n",
       "         [ 1.4500e+00],\n",
       "         [ 3.4209e-01],\n",
       "         [ 7.0579e-01],\n",
       "         [ 2.0493e-01],\n",
       "         [-2.3689e-01],\n",
       "         [-5.1909e-01],\n",
       "         [ 3.0714e-01],\n",
       "         [ 1.8470e-01],\n",
       "         [ 8.9601e-01],\n",
       "         [ 5.8735e-01],\n",
       "         [-8.6262e-02],\n",
       "         [ 1.4451e+00],\n",
       "         [-6.4776e-01],\n",
       "         [ 1.1442e+00],\n",
       "         [-5.6429e-01],\n",
       "         [ 6.8421e-01],\n",
       "         [ 1.6111e-01],\n",
       "         [ 6.6047e-01],\n",
       "         [ 1.2861e+00],\n",
       "         [ 9.9295e-01],\n",
       "         [ 5.2738e-01],\n",
       "         [ 7.4950e-01],\n",
       "         [ 1.5316e-01],\n",
       "         [ 8.2152e-01],\n",
       "         [ 8.8852e-01],\n",
       "         [-3.2619e-01],\n",
       "         [ 1.5464e+00],\n",
       "         [ 1.3112e+00],\n",
       "         [ 1.0504e+00],\n",
       "         [ 7.7857e-01],\n",
       "         [ 3.3675e-01],\n",
       "         [ 2.1729e-01],\n",
       "         [ 1.8144e+00],\n",
       "         [ 2.7872e-01],\n",
       "         [ 3.9580e-01],\n",
       "         [ 1.5623e+00],\n",
       "         [ 8.7949e-01],\n",
       "         [ 3.2275e-01],\n",
       "         [ 1.0116e+00],\n",
       "         [-1.6867e-01],\n",
       "         [-5.2343e-01],\n",
       "         [ 1.7627e+00],\n",
       "         [ 1.4044e+00],\n",
       "         [ 8.8946e-01],\n",
       "         [-2.4062e-01],\n",
       "         [ 1.4695e+00],\n",
       "         [-1.6136e-02],\n",
       "         [ 1.0941e+00],\n",
       "         [ 1.1191e+00],\n",
       "         [ 6.7001e-01],\n",
       "         [ 1.0353e-01],\n",
       "         [ 1.1357e+00],\n",
       "         [ 6.6035e-01],\n",
       "         [ 1.0299e+00],\n",
       "         [ 5.1421e-01],\n",
       "         [ 1.7215e+00],\n",
       "         [ 8.0312e-01],\n",
       "         [-6.7543e-01],\n",
       "         [ 1.5034e-01],\n",
       "         [ 2.3458e-02],\n",
       "         [ 1.3712e+00],\n",
       "         [ 7.9151e-01],\n",
       "         [ 9.9071e-01],\n",
       "         [ 8.5684e-01],\n",
       "         [ 6.3166e-01],\n",
       "         [ 1.6513e+00],\n",
       "         [ 3.8152e-02],\n",
       "         [-3.1227e-01],\n",
       "         [ 6.8522e-01],\n",
       "         [ 4.6565e-01],\n",
       "         [ 4.8872e-01],\n",
       "         [ 1.6385e+00],\n",
       "         [-3.3889e-01],\n",
       "         [-5.3435e-01],\n",
       "         [ 6.2475e-01],\n",
       "         [ 3.5003e-01],\n",
       "         [ 1.0110e+00],\n",
       "         [ 1.2222e+00],\n",
       "         [ 7.0992e-01],\n",
       "         [-2.6644e-01],\n",
       "         [ 1.0151e+00],\n",
       "         [ 1.0962e+00],\n",
       "         [ 4.9331e-01],\n",
       "         [ 1.0009e+00],\n",
       "         [ 1.4880e+00],\n",
       "         [ 1.1470e+00],\n",
       "         [ 5.0572e-01],\n",
       "         [ 3.1887e-01],\n",
       "         [ 1.1957e+00]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_size = torch.nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "output_maxpool = reduce_size(output_chomp1D)\n",
    "\n",
    "print(output_maxpool.shape)\n",
    "print(\"As we can see, each input single value turn into 320 values, and these are the important features of this single value. The length of the input series is disregarded, ie 5 becomes 1. So now the input series is represented by 1 number that has 320 features.\")\n",
    "output_maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "de478a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320])\n",
      "For a single value of the input series, we don't need one bracket for each learnt feature, so we squeeze out the bracket. Now the features of a single input value becomes one vector.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.1693e-01,  3.6379e-01,  6.9294e-01,  7.1109e-01,  4.5150e-01,\n",
       "          5.8228e-01,  7.4167e-01, -1.8462e-02,  3.5803e-01,  1.2853e-02,\n",
       "          8.3715e-01,  9.6151e-01,  1.3426e+00,  1.4026e-01,  1.3590e+00,\n",
       "         -2.7623e-01,  6.8790e-01,  4.7019e-01,  1.1830e+00,  2.5140e-01,\n",
       "          1.9567e-01,  1.4597e+00,  1.3383e+00, -5.3759e-01,  5.4988e-01,\n",
       "          7.0733e-01, -1.1598e-01,  7.1554e-01,  1.3418e+00,  1.6129e+00,\n",
       "          8.1021e-01,  1.6692e+00,  4.7325e-01,  2.4416e-01,  8.3897e-01,\n",
       "          1.8066e+00,  1.0460e+00,  3.9240e-01, -2.5766e-01,  5.2076e-01,\n",
       "          6.9135e-01,  8.3081e-01,  1.3088e+00,  1.8339e-01, -2.5171e-01,\n",
       "          5.8868e-01,  1.4208e+00,  1.2572e+00,  3.3689e-01,  9.2980e-02,\n",
       "          1.6370e-01,  8.2502e-01,  5.7390e-01,  1.6110e+00,  1.0459e+00,\n",
       "          3.0195e-01,  1.0264e+00, -1.5252e-01,  1.2383e+00,  2.2057e-01,\n",
       "          4.7698e-01,  6.1817e-01,  6.3510e-01,  6.7006e-01, -4.9933e-01,\n",
       "         -4.6938e-02,  1.9735e+00,  1.8451e+00,  5.5563e-01,  2.3449e-01,\n",
       "          7.9858e-01,  7.7994e-01,  6.1611e-01,  4.7622e-01,  6.5269e-02,\n",
       "          5.9199e-01,  6.9591e-01,  5.5791e-01, -3.6287e-01,  5.2771e-01,\n",
       "          6.5516e-01,  8.0739e-01,  7.6625e-01,  4.6984e-01,  1.7361e-01,\n",
       "          6.8724e-01,  4.2031e-01,  4.6878e-01,  6.8430e-01,  3.5087e-01,\n",
       "          2.7581e-01,  3.9147e-01,  7.9459e-01,  9.4337e-01,  1.1149e+00,\n",
       "          2.2130e-01,  4.6995e-01,  9.4343e-01,  6.5834e-01, -1.6554e-02,\n",
       "         -3.1730e-01,  1.4212e+00,  1.1191e+00,  8.7511e-01, -7.1412e-03,\n",
       "          5.8477e-01,  1.1458e+00, -1.8040e-01, -4.5143e-01, -4.6301e-01,\n",
       "          1.0733e+00,  1.0212e+00,  3.5933e-01,  2.8048e-01,  7.4088e-01,\n",
       "         -3.4165e-01,  4.2311e-01,  1.6497e+00, -3.7569e-01,  2.4492e-01,\n",
       "          7.1424e-01, -2.5414e-01,  4.9241e-01,  1.1746e+00,  2.3797e-01,\n",
       "          9.0168e-01,  2.7510e-01,  6.3755e-01,  1.1459e+00,  6.0371e-01,\n",
       "          2.8589e-01,  3.1010e-01,  4.7753e-01,  2.8079e-01,  2.5565e-01,\n",
       "          1.1841e+00, -8.0069e-02,  1.2626e+00, -2.7090e-01,  1.7835e+00,\n",
       "          1.0922e+00, -4.6702e-01,  1.6503e+00,  1.5074e+00,  8.1328e-01,\n",
       "          1.9918e+00, -2.9711e-01, -7.9050e-02,  1.8285e+00, -4.3808e-01,\n",
       "         -1.7964e-02,  1.6626e-01,  3.9343e-01,  6.5753e-01,  9.0115e-01,\n",
       "         -4.6730e-01, -2.0470e-01,  1.0665e+00,  7.2065e-01,  1.5306e-01,\n",
       "          3.1741e-02,  1.1100e+00, -1.4286e-01,  6.3447e-01, -2.7045e-01,\n",
       "          8.1055e-02,  1.1882e+00,  6.8817e-02,  7.6552e-01,  2.4762e-01,\n",
       "          3.1006e-01,  9.9973e-01,  1.7261e-01,  8.4041e-01,  2.3737e-01,\n",
       "          1.3231e+00, -2.2319e-01,  6.2816e-01,  1.8352e-01,  2.7439e-01,\n",
       "          4.7874e-01, -2.2742e-01,  2.1543e-01,  1.0492e+00,  4.9130e-01,\n",
       "          1.3470e+00,  1.0780e+00,  7.4307e-01,  6.7779e-01,  4.0288e-01,\n",
       "          1.0736e+00,  1.1005e+00,  3.7557e-01,  1.0527e+00,  8.0307e-01,\n",
       "          1.8311e-01, -1.8056e-01,  4.3792e-01,  1.5269e-03, -3.3987e-02,\n",
       "          9.6113e-01,  3.6616e-01,  3.3063e-01,  9.1808e-01,  3.5678e-01,\n",
       "          9.5070e-01,  2.6794e-01,  4.7959e-01,  2.3536e-01, -5.0524e-01,\n",
       "          5.8467e-01,  5.2341e-01,  3.3695e-01,  3.3868e-01, -2.3377e-01,\n",
       "          4.1551e-01,  9.3181e-01,  2.7498e-01, -5.2482e-01,  5.0299e-01,\n",
       "          1.4434e+00,  1.0428e+00,  9.3373e-01,  1.3503e+00,  7.6912e-01,\n",
       "          7.6583e-01, -1.8326e-01,  1.6715e+00,  6.0450e-01,  3.8164e-01,\n",
       "          1.4504e+00,  1.4500e+00,  3.4209e-01,  7.0579e-01,  2.0493e-01,\n",
       "         -2.3689e-01, -5.1909e-01,  3.0714e-01,  1.8470e-01,  8.9601e-01,\n",
       "          5.8735e-01, -8.6262e-02,  1.4451e+00, -6.4776e-01,  1.1442e+00,\n",
       "         -5.6429e-01,  6.8421e-01,  1.6111e-01,  6.6047e-01,  1.2861e+00,\n",
       "          9.9295e-01,  5.2738e-01,  7.4950e-01,  1.5316e-01,  8.2152e-01,\n",
       "          8.8852e-01, -3.2619e-01,  1.5464e+00,  1.3112e+00,  1.0504e+00,\n",
       "          7.7857e-01,  3.3675e-01,  2.1729e-01,  1.8144e+00,  2.7872e-01,\n",
       "          3.9580e-01,  1.5623e+00,  8.7949e-01,  3.2275e-01,  1.0116e+00,\n",
       "         -1.6867e-01, -5.2343e-01,  1.7627e+00,  1.4044e+00,  8.8946e-01,\n",
       "         -2.4062e-01,  1.4695e+00, -1.6136e-02,  1.0941e+00,  1.1191e+00,\n",
       "          6.7001e-01,  1.0353e-01,  1.1357e+00,  6.6035e-01,  1.0299e+00,\n",
       "          5.1421e-01,  1.7215e+00,  8.0312e-01, -6.7543e-01,  1.5034e-01,\n",
       "          2.3458e-02,  1.3712e+00,  7.9151e-01,  9.9071e-01,  8.5684e-01,\n",
       "          6.3166e-01,  1.6513e+00,  3.8152e-02, -3.1227e-01,  6.8522e-01,\n",
       "          4.6565e-01,  4.8872e-01,  1.6385e+00, -3.3889e-01, -5.3435e-01,\n",
       "          6.2475e-01,  3.5003e-01,  1.0110e+00,  1.2222e+00,  7.0992e-01,\n",
       "         -2.6644e-01,  1.0151e+00,  1.0962e+00,  4.9331e-01,  1.0009e+00,\n",
       "          1.4880e+00,  1.1470e+00,  5.0572e-01,  3.1887e-01,  1.1957e+00]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_squeeze = output_maxpool.squeeze(2)\n",
    "print(output_squeeze.shape)\n",
    "print(\"For a single value of the input series, we don't need one bracket for each learnt feature, so we squeeze out the bracket. Now the features of a single input value becomes one vector.\")\n",
    "output_squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "07b5a89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 160])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1652, -0.2739, -0.4565,  0.1729,  0.1193, -0.1135, -0.5626,  0.8112,\n",
       "          0.2723,  0.3060,  0.0181, -0.0086, -0.7606,  0.3186,  0.0923, -0.6831,\n",
       "         -0.2933,  0.8250, -0.2807,  0.7385,  0.4368, -0.3965, -0.1687, -0.0046,\n",
       "         -0.1016,  0.0626,  0.0928, -0.1905, -0.2685, -0.5265,  0.1580, -0.2371,\n",
       "         -0.4383, -0.0768,  0.4006,  0.3921,  0.0901,  0.0643, -0.6124,  0.3119,\n",
       "         -0.0433, -0.3946,  0.7506, -0.2220, -0.0543, -0.1472, -0.7048,  0.0361,\n",
       "         -0.4056,  0.2044, -0.9856,  0.8480,  0.4775, -0.3042,  0.3070, -0.2199,\n",
       "         -0.2530,  0.3329, -0.1046, -0.0391, -0.1909,  0.4528,  0.1514,  0.8546,\n",
       "          0.1549,  0.1124, -0.1357, -0.4681,  0.5549, -0.6133,  0.6729,  0.2290,\n",
       "         -0.2853, -0.5276, -0.6911, -0.1877,  0.1283, -1.1351,  0.0426, -0.1646,\n",
       "          0.0411, -0.5501, -0.2193,  1.1155, -0.0598, -0.2031,  0.4697, -0.0531,\n",
       "          0.3671, -0.3642, -0.7328, -0.5127,  0.1166,  0.6081, -1.3057, -0.1706,\n",
       "         -0.4864, -0.3666, -0.8191, -0.0892, -0.9194, -0.6215, -0.9918, -0.4649,\n",
       "          0.5369,  0.1887, -0.1733, -0.1151, -0.2060,  0.2855, -0.2542,  0.0417,\n",
       "         -0.5308,  0.0676, -0.6725, -0.4805,  0.8522, -0.0273,  0.3789, -0.0592,\n",
       "          0.1466, -0.0596, -0.3421, -0.5012, -0.2578,  0.0712, -0.2502,  0.3100,\n",
       "          0.1210, -0.4133, -0.1843,  0.3593,  0.5395, -0.9425,  0.1970,  0.6349,\n",
       "          0.0168, -0.2174,  0.2540, -0.1419,  0.7738,  0.4009,  0.2635,  0.0439,\n",
       "          0.6509,  0.2335, -0.3948,  0.0765,  0.0745, -0.5950,  0.3804,  0.7493,\n",
       "          0.2682, -0.0266,  0.7522, -0.4963, -1.0460,  0.0500,  0.4016,  0.8221]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user-defined parameter which is the length they want their latent representation to be\n",
    "reduced_size = 160\n",
    "out_channels=320\n",
    "out_features = out_channels\n",
    "\n",
    "# Fracheschi messed up the order of in_features and out_features. I switched to correct one here.\n",
    "linear = torch.nn.Linear(in_features = out_channels, out_features = reduced_size)\n",
    "output_linear = linear(output_squeeze)\n",
    "\n",
    "print(output_linear.shape)\n",
    "output_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8f6ef8",
   "metadata": {},
   "source": [
    "# When there is NaN value in the input series\n",
    "AdaptiveMaxPool1d()will just return NaN for all inputs. <br>\n",
    "This behavior is discussed and coded via:https://github.com/pytorch/pytorch/issues/7645"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e1556eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several Conv1 layers in the whole network. All of the conv1's out_channels=40 except the last conv1's out_channel=320.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Conv1d(1, 320, kernel_size=(3,), stride=(1,), padding=(2,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are several Conv1 layers in the whole network. All of the conv1's out_channels=40 except the last conv1's out_channel=320.\")\n",
    "conv1 = torch.nn.Conv1d(in_channels=1, out_channels=320, kernel_size=3, padding=2, dilation=1)\n",
    "conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f34ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chomp1D(x, chomp_size):\n",
    "    return x[:, :, :-chomp_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "138c5da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assume we input a time series, [batchSize= 1, column number = 1, length of the series = 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5653, -0.7242, -1.2605,  2.4317, -0.9420, -0.6881,  0.2517,\n",
       "           0.3291, -0.3225, -0.8670]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_withNaN = torch.randn(1, 1, 10)\n",
    "print(\"Assume we input a time series, [batchSize= 1, column number = 1, length of the series = 10]\")\n",
    "x_withNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e9db2cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5653,     nan, -1.2605,  2.4317, -0.9420, -0.6881,  0.2517,\n",
       "           0.3291, -0.3225, -0.8670]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the 2nd value to be NaN\n",
    "x_withNaN[0,0,1] = torch.log(torch.tensor([-1.]))\n",
    "x_withNaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce88674f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5470,     nan,     nan,  ...,  0.7267,  0.4146,  0.2507],\n",
       "         [ 0.0532,     nan,     nan,  ...,  0.4395, -0.0953, -0.5949],\n",
       "         [-0.1594,     nan,     nan,  ..., -0.2250, -0.0742,  0.0822],\n",
       "         ...,\n",
       "         [ 0.3751,     nan,     nan,  ...,  0.4848,  0.5070,  0.2973],\n",
       "         [ 0.1263,     nan,     nan,  ...,  0.2080,  0.0792, -0.1374],\n",
       "         [ 0.0449,     nan,     nan,  ...,  0.3547,  0.3228, -0.2789]]],\n",
       "       grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_conv1 = conv1(x_withNaN)\n",
    "print(output_conv1.shape)\n",
    "output_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7fb25d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.5470,     nan,     nan,  ...,  0.1292,  0.4548,  0.7267],\n",
       "         [ 0.0532,     nan,     nan,  ..., -0.7530, -0.0552,  0.4395],\n",
       "         [-0.1594,     nan,     nan,  ..., -0.0361, -0.2966, -0.2250],\n",
       "         ...,\n",
       "         [ 0.3751,     nan,     nan,  ...,  0.2157,  0.2863,  0.4848],\n",
       "         [ 0.1263,     nan,     nan,  ..., -0.0043,  0.2757,  0.2080],\n",
       "         [ 0.0449,     nan,     nan,  ..., -0.4247, -0.1080,  0.3547]]],\n",
       "       grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_chomp1D = chomp1D(output_conv1, 2)\n",
    "print(output_chomp1D.shape)\n",
    "output_chomp1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b003dde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320, 1])\n",
      "As we can see, each input single value turn into 320 values, and these are the important features of this single value. The length of the input series is disregarded, ie 10 becomes 1. So now the input series is represented by 1 number that has 320 features.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan],\n",
       "         [nan]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_size = torch.nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "output_maxpool = reduce_size(output_chomp1D)\n",
    "\n",
    "print(output_maxpool.shape)\n",
    "print(\"As we can see, each input single value turn into 320 values, and these are the important features of this single value. The length of the input series is disregarded, ie 10 becomes 1. So now the input series is represented by 1 number that has 320 features.\")\n",
    "output_maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2bf0e3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 320])\n",
      "For a single value of the input series, we don't need one bracket for each learnt feature, so we squeeze out the bracket. Now the features of a single input value becomes one vector.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_squeeze = output_maxpool.squeeze(2)\n",
    "print(output_squeeze.shape)\n",
    "print(\"For a single value of the input series, we don't need one bracket for each learnt feature, so we squeeze out the bracket. Now the features of a single input value becomes one vector.\")\n",
    "output_squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9b908a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 160])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user-defined parameter which is the length they want their latent representation to be\n",
    "reduced_size = 160\n",
    "out_channels=320\n",
    "out_features = out_channels\n",
    "\n",
    "# Fracheschi messed up the order of in_features and out_features. I switched to correct one here.\n",
    "linear = torch.nn.Linear(in_features = out_channels, out_features = reduced_size)\n",
    "output_linear = linear(output_squeeze)\n",
    "\n",
    "print(output_linear.shape)\n",
    "output_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c20c83",
   "metadata": {},
   "source": [
    "# Unequal lengths vs Same length training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f86a13",
   "metadata": {},
   "source": [
    "## Same length example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4349c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assume we input a time series, [batchSize= 3, column number = 2, length of the series = 4]\n",
      "As we can see, for each training set, the corresponding series all have same lengths. ie. all col1 has length 2, all col2 has length 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8544, -1.0665,     nan,     nan],\n",
       "         [ 0.0670, -0.0107,  0.7018,  0.3420]],\n",
       "\n",
       "        [[ 0.6328, -0.2316,     nan,     nan],\n",
       "         [ 0.6583,  0.9593,  0.7728, -1.2354]],\n",
       "\n",
       "        [[-0.7437,  0.7021,     nan,     nan],\n",
       "         [-1.9788, -0.1099,  1.3456,  0.8521]]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 2, 4)\n",
    "x[:, 0, 2:]=numpy.nan\n",
    "print(\"Assume we input a time series, [batchSize= 3, column number = 2, length of the series = 4]\")\n",
    "print(\"As we can see, for each training set, the corresponding series all have same lengths. ie. all col1 has length 2, all col2 has length 4\")\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646ef1d7",
   "metadata": {},
   "source": [
    "## Unequal lengths example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "021fe6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assume we input a time series, [batchSize= 3, column number = 2, length of the series = 4]\n",
      "The corresponding columns of training sets do not have the same length\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7168,  0.8649,  0.6129,     nan],\n",
       "         [ 1.4183,  1.7877, -1.1541,  0.0053]],\n",
       "\n",
       "        [[ 0.3740, -0.1801, -0.3869, -0.6879],\n",
       "         [ 1.0990,  0.5861,     nan,     nan]],\n",
       "\n",
       "        [[ 0.1607, -1.2338, -1.3170,  0.3218],\n",
       "         [ 1.6872, -0.7801,  1.5478, -2.2525]]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3, 2, 4)\n",
    "x[0, 0, 3]=numpy.nan\n",
    "x[1, 1, 2:]=numpy.nan\n",
    "print(\"Assume we input a time series, [batchSize= 3, column number = 2, length of the series = 4]\")\n",
    "print(\"The corresponding columns of training sets do not have the same length\")\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "97330077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scikit_wrappers.fit_encoder(X) will detect we have unequal lengths time series\n",
    "varying = bool(numpy.isnan(numpy.sum(x.numpy())))\n",
    "varying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32a1dc",
   "metadata": {},
   "source": [
    "Then `scikit_wrappers.fit_encoder(X`) will set:<br>\n",
    "`loss = loss_varying( batch, self.encoder, train, save_memory=save_memory )`<br>\n",
    "where `loss_varying = triplet_loss.TripletLossVaryingLength(compared_length, nb_random_samples, negative_penalty)`<br>\n",
    "The need to distinguish between varying length from same length training sets is because we need to choose samples that are within series length (NaN not included), and when lengths are varying, we need to choose different lengths accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bb0a2f",
   "metadata": {},
   "source": [
    "# Challenges \n",
    "1. Preserves only temporal order of values but not exact time of a value.\n",
    "2. Cannot handle missing value in between the time series e.g. [2, 4, 5, NaN, 8, 0]. Only accepts time series where missing values are at begining or end.\n",
    "3. Due to (1) and (2) above, it assumes equidistant time between values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df55173",
   "metadata": {},
   "source": [
    "## Solution 1 - keep embedding method, change anomaly detection method\n",
    "Use this embedding method and disregard exact time information, and a different anomaly detection method is needed.\n",
    "#### Modify current anomaly detection algorithm:\n",
    "Instead of using time interval to decide whether a value belongs or not, we can use a window of neighbor count.\n",
    "#### Other anomaly algorithms:\n",
    "- One-Class Support Vector Machine (Trained on normal data)\n",
    "- Outlier detection with Local Outlier Factor (Computes local density of data)\n",
    "- Kernel Density Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e4b59",
   "metadata": {},
   "source": [
    "## Solution 2 - change embedding method\n",
    "1. Use call gaps to engineer a dataset only contains 'normal' sensor data.\n",
    "2. Detect anomalies using method in paper \"Learning Neural Representations for Network Anomaly Detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0aa46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a45ba73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Paws\\\\Desktop\\\\MasterProject\\\\Franceschi',\n",
       " 'C:\\\\Users\\\\Paws\\\\Anaconda3\\\\envs\\\\python3_8\\\\python38.zip',\n",
       " 'C:\\\\Users\\\\Paws\\\\Anaconda3\\\\envs\\\\python3_8\\\\DLLs',\n",
       " 'C:\\\\Users\\\\Paws\\\\Anaconda3\\\\envs\\\\python3_8\\\\lib',\n",
       " 'C:\\\\Users\\\\Paws\\\\Anaconda3\\\\envs\\\\python3_8',\n",
       " '',\n",
       " 'C:\\\\Users\\\\Paws\\\\Anaconda3\\\\envs\\\\python3_8\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\Paws\\\\Anaconda3\\\\envs\\\\python3_8\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\Paws\\\\Anaconda3\\\\envs\\\\python3_8\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\Paws\\\\Anaconda3\\\\envs\\\\python3_8\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\Paws\\\\Anaconda3\\\\envs\\\\python3_8\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\Paws\\\\.ipython',\n",
       " 'C:\\\\Users\\\\Paws\\\\Desktop\\\\MasterProject\\\\Franceschi']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf738f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Paws\\\\Desktop\\\\MasterProject\\\\Franceschi'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bdc1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
